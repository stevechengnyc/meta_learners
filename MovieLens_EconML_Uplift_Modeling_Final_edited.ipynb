{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "890f27a2",
      "metadata": {
        "id": "890f27a2"
      },
      "source": [
        "# Uplift Modeling with EconML using MovieLens 1M\n",
        "This notebook downloads MovieLens 1M data, simulates treatment and renewal outcomes, introduces missing data, imputes values, and trains S-, T-, and X-Learners using different base learners."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall  econml scikit-learn pandas numpy"
      ],
      "metadata": {
        "id": "K0LlU7EAl2MQ"
      },
      "id": "K0LlU7EAl2MQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install --no-cache-dir  econml scikit-learn pandas numpy"
      ],
      "metadata": {
        "id": "TgXgiECEEdn3"
      },
      "id": "TgXgiECEEdn3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1e232db",
      "metadata": {
        "id": "e1e232db"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from econml.metalearners import SLearner, TLearner, XLearner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract MovieLens 1M dataset\n",
        "!pip install wget\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip -o ml-1m.zip -d ml-1m"
      ],
      "metadata": {
        "id": "L7Ej4YSDiJXX"
      },
      "id": "L7Ej4YSDiJXX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract MovieLens 1M dataset\n",
        "# The wget and unzip commands appear to be working correctly based on your output.\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip -o ml-1m.zip -d ml-1m\n",
        "\n",
        "# Add checks to verify if the directory and file exist\n",
        "import os\n",
        "\n",
        "# Correct the path to reflect the nested directory structure\n",
        "if os.path.exists('ml-1m/ml-1m/ratings.dat'):\n",
        "    print(\"ml-1m/ml-1m/ratings.dat found. Proceeding to load data.\")\n",
        "else:\n",
        "    print(\"Error: ml-1m/ml-1m/ratings.dat not found. Please check the extraction path.\")\n",
        "    # If the file is still not found after correcting the path, there might be\n",
        "    # a deeper issue with the unzip process or disk.\n",
        "    # import sys\n",
        "    # sys.exit(1) # Uncomment to exit the notebook execution if the file is not found"
      ],
      "metadata": {
        "id": "35AQ9oMmFMKp"
      },
      "id": "35AQ9oMmFMKp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848b323c",
      "metadata": {
        "id": "848b323c"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "ratings = pd.read_csv('ml-1m//ml-1m/ratings.dat', sep='::', engine='python',\n",
        "                      names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
        "users = pd.read_csv('ml-1m/ml-1m/users.dat', sep='::', engine='python',\n",
        "                    names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'])\n",
        "# Specify the encoding as 'latin-1' or 'ISO-8859-1' for the movies.dat file\n",
        "#movies = pd.read_csv('ml-1m/ml-1m/movies.dat', sep='::', engine='python',\n",
        "#                     names=['MovieID', 'Title', 'Genres'], encoding='latin-1')\n",
        "#df = ratings.merge(users, on='UserID').merge(movies, on='MovieID')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the encoding as 'latin-1' or 'ISO-8859-1' for the movies.dat file\n",
        "movies = pd.read_csv('ml-1m/ml-1m/movies.dat', sep='::', engine='python',\n",
        "                     names=['MovieID', 'Title', 'Genres'], encoding='latin-1')\n",
        "#df = ratings.merge(users, on='UserID').merge(movies, on='MovieID')"
      ],
      "metadata": {
        "id": "uteFPZp4KMMH"
      },
      "id": "uteFPZp4KMMH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge ratings, users, and movies\n",
        "df = ratings.merge(users, on = 'UserID').merge(movies, on = 'MovieID')\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "ZhSSefpZKMXX"
      },
      "id": "ZhSSefpZKMXX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature creation\n",
        "np.random.seed(42)\n",
        "df['WatchTime'] = df['Rating'] * np.random.uniform(15, 30, size=len(df)).astype(int)\n"
      ],
      "metadata": {
        "id": "T6MyIB50J-21"
      },
      "id": "T6MyIB50J-21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(2)"
      ],
      "metadata": {
        "id": "K92t3TNqJ-54"
      },
      "id": "K92t3TNqJ-54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Timestamp_Date'] = pd.to_datetime(df['Timestamp'], unit='s').dt.strftime('%Y-%m-%d')"
      ],
      "metadata": {
        "id": "tgCF6AR1n94J"
      },
      "id": "tgCF6AR1n94J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(3)"
      ],
      "metadata": {
        "id": "5mu5bc3uoHNv"
      },
      "id": "5mu5bc3uoHNv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TenureMonths'] = (df['Timestamp'] - df['Timestamp'].min()) // (60*60*24*30)"
      ],
      "metadata": {
        "id": "1GCaV3qNoVuH"
      },
      "id": "1GCaV3qNoVuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(3)"
      ],
      "metadata": {
        "id": "sX0EpPq2oVxp"
      },
      "id": "sX0EpPq2oVxp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regenerate ages with randome integers between 18-69\n",
        "df2 = pd.DataFrame()\n",
        "df2['UserID'] = df['UserID'].drop_duplicates()\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "8fTllZeFotP1"
      },
      "id": "8fTllZeFotP1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Age'] = np.random.randint(18, 70, df2.shape[0])\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "egHi67-r0bcp"
      },
      "id": "egHi67-r0bcp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_user = df.merge(df2, on = 'UserID', how = 'left')\n",
        "df_user.sample(5)"
      ],
      "metadata": {
        "id": "CqtwK2Mn1dWy"
      },
      "id": "CqtwK2Mn1dWy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_user = df_user.drop('Age_x', axis= 1).rename(columns = {'Age_y':'Age'})\n",
        "df_user.sample(5)"
      ],
      "metadata": {
        "id": "QnyqHSZb2X1J"
      },
      "id": "QnyqHSZb2X1J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_user.shape"
      ],
      "metadata": {
        "id": "qEw0qCID1yS1"
      },
      "id": "qEw0qCID1yS1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cba61f",
      "metadata": {
        "id": "52cba61f"
      },
      "outputs": [],
      "source": [
        "# Feature creation\n",
        "user_features = df_user.groupby('UserID').agg({\n",
        "    'WatchTime': 'sum',\n",
        "    'MovieID': 'nunique',\n",
        "    'TenureMonths': 'max',\n",
        "    'Age': 'first',\n",
        "    'Occupation': 'first'\n",
        "}).rename(columns={'WatchTime': 'TotalWatchTime', 'MovieID': 'UniqueMovies'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_features.sample(5)"
      ],
      "metadata": {
        "id": "9bF5mwls1Ym2"
      },
      "id": "9bF5mwls1Ym2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduce and impute missing data\n",
        "user_features.loc[user_features.sample(frac=0.1).index, 'TotalWatchTime'] = np.nan\n",
        "user_features.sample(10)"
      ],
      "metadata": {
        "id": "qdEQ7pYgJ9zd"
      },
      "id": "qdEQ7pYgJ9zd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features['TotalWatchTime'].isnull().sum()"
      ],
      "metadata": {
        "id": "zNAwP6N6DjMM"
      },
      "id": "zNAwP6N6DjMM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features.loc[user_features.sample(frac=0.1).index, 'TenureMonths'] = np.nan\n",
        "user_features.sample(15)"
      ],
      "metadata": {
        "id": "5CZQai0DDOMe"
      },
      "id": "5CZQai0DDOMe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6bbdadf",
      "metadata": {
        "id": "a6bbdadf"
      },
      "outputs": [],
      "source": [
        "# Introduce and impute missing data\n",
        "user_features['TotalWatchTime'] =user_features['TotalWatchTime'].fillna(user_features['TotalWatchTime'].median())\n",
        "user_features['TenureMonths']= user_features['TenureMonths'].fillna(user_features['TenureMonths'].median())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_features['treatment'] = np.random.binomial(1, 0.5, size=len(user_features))\n",
        "engaged = user_features['TotalWatchTime'] > user_features['TotalWatchTime'].median()"
      ],
      "metadata": {
        "id": "kE0CQTX0vdTw"
      },
      "id": "kE0CQTX0vdTw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engaged.head()"
      ],
      "metadata": {
        "id": "_DG3L0Z5vg5B"
      },
      "id": "_DG3L0Z5vg5B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_rate = 0.2\n",
        "uplift = 0.15 * ((user_features['treatment'] == 1) & engaged).astype(float)\n",
        "uplift.head(2)"
      ],
      "metadata": {
        "id": "Zfi_xSr6vfGz"
      },
      "id": "Zfi_xSr6vfGz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9256a93",
      "metadata": {
        "id": "b9256a93"
      },
      "outputs": [],
      "source": [
        "# Simulate treatment and renewal\n",
        "user_features['treatment'] = np.random.binomial(1, 0.5, size=len(user_features))\n",
        "engaged = user_features['TotalWatchTime'] > user_features['TotalWatchTime'].median()\n",
        "base_rate = 0.2\n",
        "uplift = 0.15 * ((user_features['treatment'] == 1) & engaged).astype(float)\n",
        "user_features['renewed'] = np.random.binomial(1, base_rate + uplift)\n",
        "X = user_features[['TenureMonths', 'TotalWatchTime', 'UniqueMovies']]\n",
        "T = user_features['treatment'].values\n",
        "Y = user_features['renewed'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T.shape, type(T), T"
      ],
      "metadata": {
        "id": "fghVNNDT7qFl"
      },
      "id": "fghVNNDT7qFl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b3fb79",
      "metadata": {
        "id": "06b3fb79"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, T_train, T_test, Y_train, Y_test = train_test_split(X, T, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(2)"
      ],
      "metadata": {
        "id": "AuK0RyM1a0uY"
      },
      "id": "AuK0RyM1a0uY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.select_dtypes(include=['number']).columns"
      ],
      "metadata": {
        "id": "CZKakU5ZbbwV"
      },
      "id": "CZKakU5ZbbwV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling\n",
        "# # Preprocessing\n",
        "# numeric_features = [\"tenure_months\", \"prior_engagement_score\", \"weekly_watch_hours\", \"num_devices\"]\n",
        "# categorical_features = [\"device_type\", \"payment_method\", \"account_type\", \"region\", \"has_kids_profile\", \"promo_eligible\"]\n",
        "\n",
        "# preprocessor = ColumnTransformer([\n",
        "#     (\"num\", StandardScaler(), numeric_features),\n",
        "#     (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "# ])\n",
        "\n",
        "# # Fit and transform\n",
        "# X_train_proc = preprocessor.fit_transform(X_train)\n",
        "# X_test_proc = preprocessor.transform(X_test)\n",
        "# # 🎯 Evaluate both\n",
        "# print(\"Sklearn GBM:\")\n",
        "# print(classification_report(y_test, sk_gbm.predict(X_test_proc)))\n",
        "# print(\"AUC:\", roc_auc_score(y_test, sk_gbm.predict_proba(X_test_proc)[:, 1]))\n"
      ],
      "metadata": {
        "id": "IEd8gWL4X_xM"
      },
      "id": "IEd8gWL4X_xM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, roc_auc_score"
      ],
      "metadata": {
        "id": "WJtyzkQHb1NQ"
      },
      "id": "WJtyzkQHb1NQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features  = X_train.select_dtypes(include=['number']).columns.tolist()\n",
        "#cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numeric_features)\n",
        " #   (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "])\n",
        "\n",
        "# Fit and transform\n",
        "X_train_proc = preprocessor.fit_transform(X_train)\n",
        "X_test_proc = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "FLGc7I1nYeZC"
      },
      "id": "FLGc7I1nYeZC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': [ 'liblinear'],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'max_iter': [100, 200,500,1000]\n",
        "    }\n",
        "\n",
        "lr_grid = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
        "lr_grid.fit(X_train_proc, Y_train)\n",
        "best_lr = lr_grid.best_estimator_"
      ],
      "metadata": {
        "id": "P6YabzS5cKRV"
      },
      "id": "P6YabzS5cKRV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr_grid.best_score_, lr_grid.best_params_"
      ],
      "metadata": {
        "id": "ISrG4fbtce-T"
      },
      "id": "ISrG4fbtce-T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr"
      ],
      "metadata": {
        "id": "wTYbiEn69Lzk"
      },
      "id": "wTYbiEn69Lzk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train learners\n",
        "from econml.metalearners import SLearner, TLearner, XLearner # Re-import the learners\n",
        "s_learner = SLearner(overall_model=best_lr)\n",
        "s_learner.fit(Y_train, T_train, X=X_train_proc)\n",
        "s_te = s_learner.effect(X_test_proc)\n",
        "pd.DataFrame({'S_Learner': s_te}).head()"
      ],
      "metadata": {
        "id": "A2qNddeJcfBm"
      },
      "id": "A2qNddeJcfBm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# param_grid = {\n",
        "#     'C': [0.01, 0.1, 1, 10, 100],\n",
        "#     'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "#     'solver': [ 'saga'],\n",
        "#     'class_weight': [None, 'balanced'],\n",
        "#     'max_iter': [10000, 20000,50000],\n",
        "#      'l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
        "# }\n",
        "\n",
        "# lr_grid = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
        "# lr_grid.fit(X_train_proc, Y_train)\n",
        "# best_lr = lr_grid.best_estimator_"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wcGc1Wx8UBGa"
      },
      "id": "wcGc1Wx8UBGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d90cd1d",
      "metadata": {
        "id": "0d90cd1d"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning\n",
        "# lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid={'C': [0.01, 0.1, 1, 10]}, cv=3)\n",
        "# lr_grid.fit(X_train, Y_train)\n",
        "# best_lr = lr_grid.best_estimator_\n",
        "\n",
        "rf_random = RandomizedSearchCV(RandomForestRegressor(random_state=42),\n",
        "    param_distributions={'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
        "    n_iter=4, cv=3, random_state=42)\n",
        "rf_random.fit(X_train, Y_train)\n",
        "best_rf = rf_random.best_estimator_\n",
        "\n",
        "gb_grid = GridSearchCV(GradientBoostingRegressor(random_state=42),\n",
        "    param_grid={'n_estimators': [100, 150], 'learning_rate': [0.05, 0.1]}, cv=3)\n",
        "gb_grid.fit(X_train, Y_train)\n",
        "best_gb = gb_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04cfa469",
      "metadata": {
        "id": "04cfa469"
      },
      "outputs": [],
      "source": [
        "# Train learners\n",
        "from econml.metalearners import SLearner, TLearner, XLearner # Re-import the learners\n",
        "#s_learner = SLearner(best_lr)\n",
        "t_learner = TLearner(models = best_rf)\n",
        "x_learner = XLearner(models = best_gb)\n",
        "#s_learner.fit(Y_train, T_train, X=X_train)\n",
        "t_learner.fit(Y_train, T_train, X=X_train)\n",
        "x_learner.fit(Y_train, T_train, X=X_train)\n",
        "#s_te = s_learner.effect(X_test)\n",
        "t_te = t_learner.effect(X_test)\n",
        "x_te = x_learner.effect(X_test)\n",
        "#pd.DataFrame({'S_Learner': s_te, 'T_Learner': t_te, 'X_Learner': x_te}).head()\n",
        "pd.DataFrame({ 'T_Learner': t_te, 'X_Learner': x_te}).head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4aZehnHghKB"
      },
      "id": "u4aZehnHghKB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}