{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Deep Causal Models with EconML: DRLearner and DeepIV (Colab Version)\n",
    "\n",
    "# üì¶ Install dependencies\n",
    "!pip install econml xgboost scikit-learn pandas matplotlib seaborn torch\n",
    "\n",
    "# üìÅ Upload your data: peacock_user_data_with_renewed_and_propensity.csv\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# üìä Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from econml.dr import DRLearner\n",
    "from econml.iv.nnet import DeepIVEstimator\n",
    "from econml.utilities import hstack\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# üì• Load data\n",
    "df = pd.read_csv(\"peacock_user_data_with_renewed_and_propensity.csv\")\n",
    "\n",
    "# Feature setup\n",
    "X = df.drop(columns=[\"user_id\", \"assigned_promo\", \"renewed\", \"propensity_score\"])\n",
    "T = df[\"assigned_promo\"]\n",
    "Y = df[\"renewed\"]\n",
    "\n",
    "# Known CATE for evaluation\n",
    "tau_x = (\n",
    "    0.4\n",
    "    - 0.7 * df[\"prior_engagement_score\"]\n",
    "    + 0.1 * (df[\"device_type\"] == \"roku\").astype(int)\n",
    "    + 0.05 * (df[\"has_kids_profile\"] == 1).astype(int)\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test, tau_train, tau_test = train_test_split(\n",
    "    X, T, Y, tau_x, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Column Transformer\n",
    "numeric_features = [\"tenure_months\", \"prior_engagement_score\", \"weekly_watch_hours\", \"num_devices\"]\n",
    "categorical_features = [\"device_type\", \"payment_method\", \"account_type\", \"region\", \"has_kids_profile\", \"promo_eligible\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# üîß DRLearner with neural net models\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from econml.metalearners import TLearner\n",
    "from econml.models import KerasModel\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_keras_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# DRLearner\n",
    "dr_learner = DRLearner(\n",
    "    model_propensity=GradientBoostingRegressor(),\n",
    "    model_regression=GradientBoostingRegressor(),\n",
    "    model_final=KerasModel(model_builder=lambda: build_keras_model(X_train_proc.shape[1]),\n",
    "                           fit_kwargs={'epochs': 30, 'verbose': 0})\n",
    ")\n",
    "\n",
    "dr_learner.fit(Y_train, T_train, X=X_train_proc)\n",
    "cate_dr = dr_learner.effect(X_test_proc)\n",
    "\n",
    "# PEHE evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "pehe_dr = np.sqrt(mean_squared_error(tau_test, cate_dr))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(cate_dr, kde=True, bins=30)\n",
    "plt.title(f\"DRLearner (PEHE: {pehe_dr:.3f})\")\n",
    "plt.xlabel(\"Estimated CATE\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üöÄ Optional: DeepIV if IV is available (instrument z ‚â† T)\n",
    "# Simulate an instrument for demo\n",
    "Z = df[\"promo_eligible\"]\n",
    "Z_train, Z_test = train_test_split(Z, test_size=0.3, random_state=42)\n",
    "\n",
    "# DeepIV requires outcome, treatment, instrument, and covariates\n",
    "deepiv = DeepIVEstimator(\n",
    "    n_components=10,\n",
    "    m=lambda z, x: build_keras_model(x.shape[1]),\n",
    "    h=lambda t, x: build_keras_model(x.shape[1]),\n",
    "    n_samples=1,\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    first_stage_options={'epochs': 30, 'verbose': 0},\n",
    "    second_stage_options={'epochs': 30, 'verbose': 0}\n",
    ")\n",
    "\n",
    "# DeepIV fit\n",
    "deepiv.fit(Y_train, T_train, Z_train, X=X_train_proc)\n",
    "\n",
    "# Estimate CATE at T=1 vs T=0\n",
    "cate_deepiv = deepiv.effect(X_test_proc, T0=0, T1=1)\n",
    "pehe_deepiv = np.sqrt(mean_squared_error(tau_test, cate_deepiv))\n",
    "\n",
    "# Plot DeepIV\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(cate_deepiv, kde=True, bins=30)\n",
    "plt.title(f\"DeepIV (PEHE: {pehe_deepiv:.3f})\")\n",
    "plt.xlabel(\"Estimated CATE\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
