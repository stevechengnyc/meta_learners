{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890f27a2",
   "metadata": {},
   "source": [
    "# Uplift Modeling with EconML using MovieLens 1M\n",
    "This notebook downloads MovieLens 1M data, simulates treatment and renewal outcomes, introduces missing data, imputes values, and trains S-, T-, and X-Learners using different base learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f94df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install econml scikit-learn pandas numpy wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract MovieLens 1M dataset\n",
    "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip -o ml-1m.zip -d ml-1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e232db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from econml.metalearners import SLearner, TLearner, XLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', engine='python',\n",
    "                      names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', engine='python',\n",
    "                    names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'])\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', engine='python',\n",
    "                     names=['MovieID', 'Title', 'Genres'])\n",
    "df = ratings.merge(users, on='UserID').merge(movies, on='MovieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cba61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature creation\n",
    "np.random.seed(42)\n",
    "df['WatchTime'] = df['Rating'] * np.random.uniform(15, 30, size=len(df))\n",
    "df['TenureMonths'] = (df['Timestamp'] - df['Timestamp'].min()) // (60*60*24*30)\n",
    "user_features = df.groupby('UserID').agg({\n",
    "    'WatchTime': 'sum',\n",
    "    'MovieID': 'nunique',\n",
    "    'TenureMonths': 'max',\n",
    "    'Age': 'first',\n",
    "    'Occupation': 'first'\n",
    "}).rename(columns={'WatchTime': 'TotalWatchTime', 'MovieID': 'UniqueMovies'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbdadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce and impute missing data\n",
    "user_features.loc[user_features.sample(frac=0.1).index, 'TotalWatchTime'] = np.nan\n",
    "user_features.loc[user_features.sample(frac=0.1).index, 'TenureMonths'] = np.nan\n",
    "user_features['TotalWatchTime'].fillna(user_features['TotalWatchTime'].median(), inplace=True)\n",
    "user_features['TenureMonths'].fillna(user_features['TenureMonths'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9256a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate treatment and renewal\n",
    "user_features['treatment'] = np.random.binomial(1, 0.5, size=len(user_features))\n",
    "engaged = user_features['TotalWatchTime'] > user_features['TotalWatchTime'].median()\n",
    "base_rate = 0.2\n",
    "uplift = 0.15 * ((user_features['treatment'] == 1) & engaged).astype(float)\n",
    "user_features['renewed'] = np.random.binomial(1, base_rate + uplift)\n",
    "X = user_features[['TenureMonths', 'TotalWatchTime', 'UniqueMovies']]\n",
    "T = user_features['treatment'].values\n",
    "Y = user_features['renewed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test = train_test_split(X, T, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid={'C': [0.01, 0.1, 1, 10]}, cv=3)\n",
    "lr_grid.fit(X_train, Y_train)\n",
    "best_lr = lr_grid.best_estimator_\n",
    "\n",
    "rf_random = RandomizedSearchCV(RandomForestRegressor(random_state=42),\n",
    "    param_distributions={'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    n_iter=4, cv=3, random_state=42)\n",
    "rf_random.fit(X_train, Y_train)\n",
    "best_rf = rf_random.best_estimator_\n",
    "\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(random_state=42),\n",
    "    param_grid={'n_estimators': [100, 150], 'learning_rate': [0.05, 0.1]}, cv=3)\n",
    "gb_grid.fit(X_train, Y_train)\n",
    "best_gb = gb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train learners\n",
    "s_learner = SLearner(learner=best_lr)\n",
    "t_learner = TLearner(models=best_rf)\n",
    "x_learner = XLearner(models=best_gb)\n",
    "s_learner.fit(Y_train, T_train, X=X_train)\n",
    "t_learner.fit(Y_train, T_train, X=X_train)\n",
    "x_learner.fit(Y_train, T_train, X=X_train)\n",
    "s_te = s_learner.effect(X_test)\n",
    "t_te = t_learner.effect(X_test)\n",
    "x_te = x_learner.effect(X_test)\n",
    "pd.DataFrame({'S_Learner': s_te, 'T_Learner': t_te, 'X_Learner': x_te}).head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
