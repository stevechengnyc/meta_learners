{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Deep Causal Models with EconML: DRLearner and DeepIV (Colab Version)\n",
    "\n",
    "# üì¶ Install dependencies\n",
    "!pip install econml xgboost scikit-learn pandas matplotlib seaborn torch\n",
    "\n",
    "# üìÅ Upload your data: peacock_user_data_with_renewed_and_propensity.csv\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# üìä Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from econml.dr import DRLearner\n",
    "from econml.iv.nnet import DeepIVEstimator\n",
    "from econml.utilities import hstack\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# üì• Load data\n",
    "df = pd.read_csv(\"peacock_user_data_with_renewed_and_propensity.csv\")\n",
    "\n",
    "# Feature setup\n",
    "X = df.drop(columns=[\"user_id\", \"assigned_promo\", \"renewed\", \"propensity_score\"])\n",
    "T = df[\"assigned_promo\"]\n",
    "Y = df[\"renewed\"]\n",
    "\n",
    "# Known CATE for evaluation\n",
    "tau_x = (\n",
    "    0.4\n",
    "    - 0.7 * df[\"prior_engagement_score\"]\n",
    "    + 0.1 * (df[\"device_type\"] == \"roku\").astype(int)\n",
    "    + 0.05 * (df[\"has_kids_profile\"] == 1).astype(int)\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test, tau_train, tau_test = train_test_split(\n",
    "    X, T, Y, tau_x, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Column Transformer\n",
    "numeric_features = [\"tenure_months\", \"prior_engagement_score\", \"weekly_watch_hours\", \"num_devices\"]\n",
    "categorical_features = [\"device_type\", \"payment_method\", \"account_type\", \"region\", \"has_kids_profile\", \"promo_eligible\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# üîß DRLearner with neural net models\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from econml.metalearners import TLearner\n",
    "from econml.models import KerasModel\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_keras_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# DRLearner\n",
    "dr_learner = DRLearner(\n",
    "    model_propensity=GradientBoostingRegressor(),\n",
    "    model_regression=GradientBoostingRegressor(),\n",
    "    model_final=KerasModel(model_builder=lambda: build_keras_model(X_train_proc.shape[1]),\n",
    "                           fit_kwargs={'epochs': 30, 'verbose': 0})\n",
    ")\n",
    "\n",
    "dr_learner.fit(Y_train, T_train, X=X_train_proc)\n",
    "cate_dr = dr_learner.effect(X_test_proc)\n",
    "\n",
    "# PEHE evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "pehe_dr = np.sqrt(mean_squared_error(tau_test, cate_dr))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(cate_dr, kde=True, bins=30)\n",
    "plt.title(f\"DRLearner (PEHE: {pehe_dr:.3f})\")\n",
    "plt.xlabel(\"Estimated CATE\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üöÄ Optional: DeepIV if IV is available (instrument z ‚â† T)\n",
    "# Simulate an instrument for demo\n",
    "Z = df[\"promo_eligible\"]\n",
    "Z_train, Z_test = train_test_split(Z, test_size=0.3, random_state=42)\n",
    "\n",
    "# DeepIV requires outcome, treatment, instrument, and covariates\n",
    "deepiv = DeepIVEstimator(\n",
    "    n_components=10,\n",
    "    m=lambda z, x: build_keras_model(x.shape[1]),\n",
    "    h=lambda t, x: build_keras_model(x.shape[1]),\n",
    "    n_samples=1,\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    first_stage_options={'epochs': 30, 'verbose': 0},\n",
    "    second_stage_options={'epochs': 30, 'verbose': 0}\n",
    ")\n",
    "\n",
    "# DeepIV fit\n",
    "deepiv.fit(Y_train, T_train, Z_train, X=X_train_proc)\n",
    "\n",
    "# Estimate CATE at T=1 vs T=0\n",
    "cate_deepiv = deepiv.effect(X_test_proc, T0=0, T1=1)\n",
    "pehe_deepiv = np.sqrt(mean_squared_error(tau_test, cate_deepiv))\n",
    "\n",
    "# Plot DeepIV\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(cate_deepiv, kde=True, bins=30)\n",
    "plt.title(f\"DeepIV (PEHE: {pehe_deepiv:.3f})\")\n",
    "plt.xlabel(\"Estimated CATE\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà Policy Value Evaluation and Uplift-Based Targeting\n",
    "\n",
    "# Sort test users by predicted uplift (CATE)\n",
    "test_df = pd.DataFrame({\n",
    "    \"user_id\": X_test.index,\n",
    "    \"cate\": cate_preds,\n",
    "    \"true_tau\": tau_test,\n",
    "    \"treatment\": T_test,\n",
    "    \"outcome\": Y_test\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Rank by predicted CATE\n",
    "test_df_sorted = test_df.sort_values(by=\"cate\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Define budget: top 20% of users\n",
    "budget_fraction = 0.2\n",
    "n_target = int(budget_fraction * len(test_df_sorted))\n",
    "\n",
    "# Evaluate policy value\n",
    "def policy_value(df, treat_col, outcome_col):\n",
    "    return df.loc[df[treat_col] == 1, outcome_col].mean()\n",
    "\n",
    "# Scenarios\n",
    "treat_all = test_df.copy()\n",
    "treat_all[\"treatment\"] = 1\n",
    "value_all = policy_value(treat_all, \"treatment\", \"outcome\")\n",
    "\n",
    "treat_none = test_df.copy()\n",
    "treat_none[\"treatment\"] = 0\n",
    "value_none = policy_value(treat_none, \"treatment\", \"outcome\")\n",
    "\n",
    "uplift_target = test_df.copy()\n",
    "uplift_target[\"treatment\"] = 0\n",
    "uplift_target.loc[test_df_sorted.head(n_target).index, \"treatment\"] = 1\n",
    "value_targeted = policy_value(uplift_target, \"treatment\", \"outcome\")\n",
    "\n",
    "# üìä Print comparison\n",
    "print(\"Policy Value Comparison:\")\n",
    "print(f\"Treat All:    {value_all:.4f}\")\n",
    "print(f\"Treat None:   {value_none:.4f}\")\n",
    "print(f\"Uplift-Based: {value_targeted:.4f} (Top {budget_fraction*100:.0f}%)\")\n",
    "\n",
    "# Plot top uplift users\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(test_df_sorted[\"cate\"].head(n_target), bins=30, kde=True, color=\"green\")\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"Top Uplift Scores (Targeted Segment)\")\n",
    "plt.xlabel(\"Predicted Uplift (CATE)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üéØ Targeting Precision Evaluation\n",
    "\n",
    "# Define actual uplift = observed Y1 - Y0 for each user\n",
    "# Here we approximate it using true uplift tau and simulate based on prediction rank\n",
    "\n",
    "test_df_sorted[\"true_positive\"] = test_df_sorted[\"true_tau\"] > 0\n",
    "test_df_sorted[\"predicted_positive\"] = test_df_sorted[\"cate\"] > 0\n",
    "\n",
    "# Precision at top-k (top 20%)\n",
    "top_k_df = test_df_sorted.head(n_target)\n",
    "\n",
    "precision_top_k = top_k_df[\"true_positive\"].mean()\n",
    "overall_positive_rate = test_df_sorted[\"true_positive\"].mean()\n",
    "\n",
    "print(f\"Precision in Top {budget_fraction*100:.0f}%: {precision_top_k:.4f}\")\n",
    "print(f\"Overall Positive Rate: {overall_positive_rate:.4f}\")\n",
    "print(f\"Lift: {precision_top_k / overall_positive_rate:.2f}x improvement\")\n",
    "\n",
    "# Plot precision lift\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar([\"Top 20% Precision\", \"Overall Rate\"], [precision_top_k, overall_positive_rate], color=[\"blue\", \"gray\"])\n",
    "plt.title(\"Targeting Precision vs. Random\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîç Detailed SHAP Value Extraction and Plotting for Each Model\n",
    "\n",
    "# Preprocessed feature names\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# SHAP for Propensity Model (Logistic Regression)\n",
    "explainer_prop = shap.Explainer(dr._model_propensity.predict_proba, X_train_proc.toarray() if hasattr(X_train_proc, 'toarray') else X_train_proc)\n",
    "shap_values_prop = explainer_prop(X_test_proc.toarray() if hasattr(X_test_proc, 'toarray') else X_test_proc)\n",
    "\n",
    "print(\"SHAP Summary for Propensity Model:\")\n",
    "shap.plots.beeswarm(shap_values_prop, max_display=10, show=False)\n",
    "plt.title(\"SHAP Summary - Propensity Model\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP for Outcome Model (Gradient Boosting)\n",
    "explainer_reg = shap.Explainer(dr._model_regression.predict, X_train_proc)\n",
    "shap_values_reg = explainer_reg(X_test_proc)\n",
    "\n",
    "print(\"SHAP Summary for Outcome Model:\")\n",
    "shap.plots.beeswarm(shap_values_reg, max_display=10, show=False)\n",
    "plt.title(\"SHAP Summary - Outcome Model\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP for Final CATE Model (Neural Network)\n",
    "final_model_internal = dr.model_final.model_\n",
    "explainer_final = shap.Explainer(final_model_internal, X_test_proc)\n",
    "shap_values_final = explainer_final(X_test_proc)\n",
    "\n",
    "print(\"SHAP Summary for Final CATE Model:\")\n",
    "shap.plots.beeswarm(shap_values_final, max_display=10, show=False)\n",
    "plt.title(\"SHAP Summary - Final CATE Model\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
