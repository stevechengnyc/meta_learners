{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # EconML with PyTorch Neural Network Base Learners for Uplift Modeling\n",
    "# S-Learner, T-Learner, X-Learner using MLP from PyTorch\n",
    "\n",
    "# üì¶ Install dependencies\n",
    "!pip install econml xgboost scikit-learn pandas matplotlib seaborn torch\n",
    "\n",
    "# üìÅ Upload the updated dataset: peacock_user_data_with_renewed_and_propensity.csv\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# üìä Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from econml.metalearners import SLearner, TLearner, XLearner\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# üß† Define a simple feedforward neural network regressor\n",
    "class MLPRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, input_dim=None, hidden_dim=64, lr=0.001, epochs=20, batch_size=64):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.input_dim = input_dim\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def _build_model(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X).astype(np.float32)\n",
    "        y = np.array(y).reshape(-1, 1).astype(np.float32)\n",
    "        self.input_dim = X.shape[1]\n",
    "        self.model = self._build_model()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        dataset = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            for xb, yb in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                preds = self.model(xb)\n",
    "                loss = loss_fn(preds, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X).astype(np.float32)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.tensor(X)).numpy()\n",
    "        return preds.ravel()\n",
    "\n",
    "# üì• Load data\n",
    "df = pd.read_csv(\"peacock_user_data_with_renewed_and_propensity.csv\")\n",
    "X = df.drop(columns=[\"user_id\", \"assigned_promo\", \"renewed\", \"propensity_score\"])\n",
    "T = df[\"assigned_promo\"]\n",
    "Y = df[\"renewed\"]\n",
    "\n",
    "# Known ground-truth uplift function\n",
    "tau_x = (\n",
    "    0.4\n",
    "    - 0.7 * df[\"prior_engagement_score\"]\n",
    "    + 0.1 * (df[\"device_type\"] == \"roku\").astype(int)\n",
    "    + 0.05 * (df[\"has_kids_profile\"] == 1).astype(int)\n",
    ")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test, tau_train, tau_test = train_test_split(\n",
    "    X, T, Y, tau_x, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ‚öôÔ∏è Preprocess\n",
    "numeric_features = [\"tenure_months\", \"prior_engagement_score\", \"weekly_watch_hours\", \"num_devices\"]\n",
    "categorical_features = [\"device_type\", \"payment_method\", \"account_type\", \"region\", \"has_kids_profile\", \"promo_eligible\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# Neural Net base model\n",
    "base_nn = MLPRegressor(input_dim=X_train_proc.shape[1], hidden_dim=64, lr=0.001, epochs=30)\n",
    "\n",
    "# Learners\n",
    "s_learner = SLearner(model=base_nn)\n",
    "t_learner = TLearner(models=base_nn)\n",
    "x_learner = XLearner(models=base_nn)\n",
    "\n",
    "# Fit\n",
    "s_learner.fit(Y_train, T_train, X=X_train_proc)\n",
    "t_learner.fit(Y_train, T_train, X=X_train_proc)\n",
    "x_learner.fit(Y_train, T_train, X=X_train_proc)\n",
    "\n",
    "# Predict CATE\n",
    "cate_s = s_learner.effect(X_test_proc)\n",
    "cate_t = t_learner.effect(X_test_proc)\n",
    "cate_x = x_learner.effect(X_test_proc)\n",
    "\n",
    "# Evaluate PEHE\n",
    "pehe_s = np.sqrt(mean_squared_error(tau_test, cate_s))\n",
    "pehe_t = np.sqrt(mean_squared_error(tau_test, cate_t))\n",
    "pehe_x = np.sqrt(mean_squared_error(tau_test, cate_x))\n",
    "\n",
    "# üìä Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, (name, cates, pehe) in enumerate([\n",
    "    (\"S-Learner\", cate_s, pehe_s),\n",
    "    (\"T-Learner\", cate_t, pehe_t),\n",
    "    (\"X-Learner\", cate_x, pehe_x)\n",
    "]):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.histplot(cates, kde=True, bins=30)\n",
    "    plt.title(f\"{name} (PEHE: {pehe:.3f})\")\n",
    "    plt.xlabel(\"Estimated CATE\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
